{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from wvaegan_gp.model_vector import Encoder, Decoder, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ\n",
    "OUTPUT_DIR = 'wvaegan_gp/results'\n",
    "DATA_PATH = '../motor_dataset_20221018st'\n",
    "N_CLASSES = 1\n",
    "COORD_SIZE = 932  # 座標の数\n",
    "LATENT_DIM = 1\n",
    "done_epoch = 45000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "coords_shape = (1, COORD_SIZE)\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "torques_npz = np.load(f\"{DATA_PATH}/labels.npz\")\n",
    "coords_npz = np.load(f\"{DATA_PATH}/coords.npz\")\n",
    "torques = torques_npz[torques_npz.files[0]]\n",
    "torque_mean = torques_npz[torques_npz.files[2]]\n",
    "torque_std = torques_npz[torques_npz.files[3]]\n",
    "coords = coords_npz[coords_npz.files[0]]\n",
    "coord_mean = coords_npz[coords_npz.files[1]]\n",
    "coord_std = coords_npz[coords_npz.files[2]]\n",
    "\n",
    "max_torque = torques.max()\n",
    "min_torque = torques.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Encoder:\n\tMissing key(s) in state_dict: \"model.12.weight\", \"model.12.bias\", \"model.12.running_mean\", \"model.12.running_var\", \"model.14.weight\", \"model.14.bias\". \n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([256, 933]) from checkpoint, the shape in current model is torch.Size([1024, 933]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.2.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([512, 1024]).\n\tsize mismatch for model.11.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for model.11.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m G_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/decoder_params_dim\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLATENT_DIM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vector_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdone_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m D_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/discriminator_params_dim\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLATENT_DIM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vector_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdone_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m encoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     12\u001b[0m decoder\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(G_PATH, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\田村征之\\Desktop\\research\\VAEGAN_motor\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   1600\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1601\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1605\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1606\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Encoder:\n\tMissing key(s) in state_dict: \"model.12.weight\", \"model.12.bias\", \"model.12.running_mean\", \"model.12.running_var\", \"model.14.weight\", \"model.14.bias\". \n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([256, 933]) from checkpoint, the shape in current model is torch.Size([1024, 933]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.2.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([512, 1024]).\n\tsize mismatch for model.11.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for model.11.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([64])."
     ]
    }
   ],
   "source": [
    "encoder = Encoder(LATENT_DIM, COORD_SIZE)\n",
    "decoder = Decoder(LATENT_DIM, COORD_SIZE)\n",
    "discriminator = Discriminator(COORD_SIZE)\n",
    "\n",
    "E_PATH = f\"{OUTPUT_DIR}/encoder_params_dim{LATENT_DIM}_vector_{done_epoch}\"\n",
    "G_PATH = f\"{OUTPUT_DIR}/decoder_params_dim{LATENT_DIM}_vector_{done_epoch}\"\n",
    "D_PATH = f\"{OUTPUT_DIR}/discriminator_params_dim{LATENT_DIM}_vector_{done_epoch}\"\n",
    "\n",
    "encoder.load_state_dict(torch.load(E_PATH, map_location=torch.device('cpu')))\n",
    "encoder.eval()\n",
    "\n",
    "decoder.load_state_dict(torch.load(G_PATH, map_location=torch.device('cpu')))\n",
    "decoder.eval()\n",
    "\n",
    "discriminator.load_state_dict(torch.load(D_PATH, map_location=torch.device('cpu')))\n",
    "discriminator.eval()\n",
    "\n",
    "if cuda:\n",
    "    print(\"use GPU\")\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_torque = 0.180\n",
    "min_torque = 0.010\n",
    "step_torque = 0.010\n",
    "\n",
    "max_latent = 1.00\n",
    "min_latent = -1.00\n",
    "step_latent = 0.20\n",
    "\n",
    "torque_array = np.arange(min_torque, max_torque+step_torque, step_torque)\n",
    "\n",
    "# 潜在変数が1のとき\n",
    "latent_array = np.arange(min_latent, max_latent+step_latent, step_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json(x_array, y_array):\n",
    "    output_json = []\n",
    "    for x, y in zip(x_array, y_array):\n",
    "        output_json.append({'x': x, 'y': y})\n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_json = {}\n",
    "for torque in torque_array:\n",
    "\n",
    "    torque_idx = f'{torque:.3f}'\n",
    "    coords_json[torque_idx] = {}\n",
    "\n",
    "    torque_standardized = (torque-torque_mean) / torque_std\n",
    "    torque_standardized = torque_standardized.reshape([1, 1])\n",
    "    torque_standardized = Variable(FloatTensor(torque_standardized))\n",
    "\n",
    "    z = Variable(FloatTensor(rng.standard_normal(size=(1, COORD_SIZE))))\n",
    "    mus, log_variances = encoder(z, torque_standardized)\n",
    "    variances = torch.exp(log_variances * 0.5)\n",
    "\n",
    "    for latent in latent_array:\n",
    "        \n",
    "        latent_idx = f'{latent:.2f}'\n",
    "        if latent_idx =='-0.00':\n",
    "            latent_idx = '0.00'\n",
    "\n",
    "        coords_json[torque_idx][latent_idx] = {}\n",
    "        latent = latent.reshape([1, -1])\n",
    "        Z_p = Variable(FloatTensor(latent))\n",
    "        Z = Z_p * variances + mus\n",
    "        en_coords = decoder(Z, torque_standardized).cpu().detach().numpy()[0][0]\n",
    "        coords = en_coords*coord_std+coord_mean  # 標準化を戻す\n",
    "\n",
    "        coords_json[torque_idx][latent_idx]['magnet'] = make_json(coords[:136], coords[136:272])  # 磁石\n",
    "        coords_json[torque_idx][latent_idx]['holl'] = make_json(coords[272:272+184], coords[272+184:272+368])  # 穴\n",
    "        # coords_json[torque_idx][latent_idx]['outline'] = make_json(coords[272+368:272+368+146], coords[272+368+146:])  # 外枠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../app/frontend/src/assets/coords.json', 'w') as f:\n",
    "    json.dump(coords_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b56baf3bbbadfc729dba1939f1adb96728830b98200cd19cb7cf0f04b7e6ce9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
